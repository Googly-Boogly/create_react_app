from typing import Dict, Any, Callable, Optional
from global_code.singleton import State
from openai import OpenAI

client = OpenAI(api_key=State.config["OPENAI"]["API_KEY"])


def handle_openai_call(call_type: str, input_text: str, config: Dict[str, Any],
                       tools: Optional[Dict[str, Callable]] = None,
                       **kwargs) -> Any:
    """
    Handles API calls to OpenAI
    :param call_type: needs to be llm
    :param input_text: the prompt
    :param config: this should include the model you want to use (with key as model, and value as the model name)
    Check this link for updated models: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
    Models available: "gpt-4-0125-preview", "gpt-3.5-turbo", "gpt-4", "gpt-3.5-turbo-0125", "gpt-4-1106-vision-preview",
    "gpt-4-turbo-preview",
    type_of_response: only_code, only_text, function_calling.
    only_code: returns only the code generated by the LLM. LLM should only output the code.
    only_text: returns only the text generated by the LLM. LLM should only output the text.
    function_calling: returns the function call to the code generated by the LLM. LLM should only output the JSON.
    :param tools: NOT SUPPORTED YET
    :param kwargs: max_tokens, temperature
    :return: the response from the OpenAI API
    """
    if call_type != "llm":
        raise ValueError("OpenAI provider currently only supports LLM calls")
    type_of_response = config.get("type_of_response")
    temperature = kwargs.get("temperature", 0.7)
    if type_of_response == "function_calling":
        temperature = 0.1
    model = config.get("model")

    if model not in ["gpt-4-0125-preview", "gpt-3.5-turbo", "gpt-4", "gpt-3.5-turbo-0125", "gpt-4-1106-vision-preview",
                     "gpt-4-turbo-preview", "gpt-3.5-turbo-16k"]:
        raise ValueError("Unsupported model specified")

    response = client.chat.completions.create(model=config['model'],
                                         messages=[{"role": "user", "content": input_text}],
                                              temperature=temperature)

    if type_of_response == "only_code" or type_of_response == "code_only":
        return response.choices[0].message.content
    elif type_of_response == "only_text" or type_of_response == "text_only":
        return response.choices[0].message.content
    elif type_of_response == "function_calling":

        return response.choices[0].message.content

    return response
